# Nautilus Trading Platform - Monitoring & Alerting Configuration

version: '3.8'

services:
  # Prometheus - Metrics Collection
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: nautilus-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/prometheus/rules/:/etc/prometheus/rules/
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    networks:
      - monitoring

  # Grafana - Visualization Dashboard
  grafana:
    image: grafana/grafana:10.1.0
    container_name: nautilus-grafana
    restart: unless-stopped
    ports:
      - "3002:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin123}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    networks:
      - monitoring

  # AlertManager - Alert Routing
  alertmanager:
    image: prom/alertmanager:v0.25.0
    container_name: nautilus-alertmanager
    restart: unless-stopped
    ports:
      - "9093:9093"
    volumes:
      - ./monitoring/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
    networks:
      - monitoring

  # Node Exporter - System Metrics
  node-exporter:
    image: prom/node-exporter:v1.6.0
    container_name: nautilus-node-exporter
    restart: unless-stopped
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - monitoring

  # cAdvisor - Container Metrics
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.2
    container_name: nautilus-cadvisor
    restart: unless-stopped
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    privileged: true
    devices:
      - /dev/kmsg
    networks:
      - monitoring

  # Loki - Log Aggregation
  loki:
    image: grafana/loki:2.9.0
    container_name: nautilus-loki
    restart: unless-stopped
    ports:
      - "3100:3100"
    volumes:
      - ./monitoring/loki/loki.yml:/etc/loki/local-config.yaml
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - monitoring

  # Promtail - Log Shipper
  promtail:
    image: grafana/promtail:2.9.0
    container_name: nautilus-promtail
    restart: unless-stopped
    volumes:
      - ./monitoring/promtail/promtail.yml:/etc/promtail/config.yml
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    command: -config.file=/etc/promtail/config.yml
    networks:
      - monitoring

  # Uptime Kuma - External Monitoring
  uptime-kuma:
    image: louislam/uptime-kuma:1.23.0
    container_name: nautilus-uptime-kuma
    restart: unless-stopped
    ports:
      - "3001:3001"
    volumes:
      - uptime_data:/app/data
    networks:
      - monitoring

volumes:
  prometheus_data:
  grafana_data:
  alertmanager_data:
  loki_data:
  uptime_data:

networks:
  monitoring:
    driver: bridge

---
# Prometheus Configuration (prometheus.yml)
global:
  scrape_interval: 15s
  evaluation_interval: 15s

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

rule_files:
  - "/etc/prometheus/rules/*.yml"

scrape_configs:
  # Prometheus itself
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Node Exporter - System Metrics
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  # cAdvisor - Container Metrics
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']

  # Nautilus Backend Application
  - job_name: 'nautilus-backend'
    static_configs:
      - targets: ['nautilus-backend:8000']
    metrics_path: '/metrics'
    scrape_interval: 5s

  # Interactive Brokers Gateway
  - job_name: 'ib-gateway'
    static_configs:
      - targets: ['ib-gateway:4001']
    scrape_interval: 10s

  # PostgreSQL Database
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']
    scrape_interval: 30s

  # Redis Cache
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
    scrape_interval: 30s

---
# AlertManager Configuration (alertmanager.yml)
global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@nautilus-trading.com'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'
  routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
    - match:
        severity: warning
      receiver: 'warning-alerts'

receivers:
  - name: 'web.hook'
    webhook_configs:
      - url: 'http://127.0.0.1:5001/'

  - name: 'critical-alerts'
    email_configs:
      - to: 'admin@nautilus-trading.com'
        subject: 'CRITICAL: Nautilus Trading Alert'
        body: |
          Alert: {{ .GroupLabels.alertname }}
          Summary: {{ .CommonAnnotations.summary }}
          Description: {{ .CommonAnnotations.description }}
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#trading-alerts'
        title: 'CRITICAL: Nautilus Trading Alert'
        text: '{{ .CommonAnnotations.summary }}'

  - name: 'warning-alerts'
    email_configs:
      - to: 'monitoring@nautilus-trading.com'
        subject: 'WARNING: Nautilus Trading Alert'
        body: |
          Alert: {{ .GroupLabels.alertname }}
          Summary: {{ .CommonAnnotations.summary }}

---
# Trading Platform Alert Rules (trading-alerts.yml)
groups:
  - name: trading_system_alerts
    rules:
      # Critical System Alerts
      - alert: TradingSystemDown
        expr: up{job="nautilus-backend"} == 0
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "Trading system is down"
          description: "The Nautilus trading backend has been down for more than 30 seconds"

      - alert: DatabaseDown
        expr: up{job="postgres"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Database is down"
          description: "PostgreSQL database is not responding"

      - alert: HighAPILatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High API latency detected"
          description: "95th percentile latency is above 500ms for 2 minutes"

      # Trading Performance Alerts
      - alert: OrderExecutionFailure
        expr: rate(trading_orders_failed_total[5m]) > 0.1
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "High order execution failure rate"
          description: "Order execution failure rate is above 10% for 1 minute"

      - alert: UnusualTradingVolume
        expr: rate(trading_volume_total[5m]) > 1000 or rate(trading_volume_total[5m]) < 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Unusual trading volume detected"
          description: "Trading volume is outside normal parameters"

      # System Resource Alerts
      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is above 85% for 5 minutes"

      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage"
          description: "CPU usage is above 80% for 10 minutes"

      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 < 15
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Disk space low"
          description: "Disk space is below 15%"

      # Trading Strategy Alerts
      - alert: StrategyPerformanceDown
        expr: trading_strategy_pnl_daily < -1000
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: "Strategy performance degradation"
          description: "Daily P&L is below -$1000 for 1 hour"

      - alert: MaxDrawdownExceeded
        expr: trading_strategy_drawdown > 0.05
        for: 30m
        labels:
          severity: critical
        annotations:
          summary: "Maximum drawdown exceeded"
          description: "Strategy drawdown exceeds 5% threshold"

---
# Grafana Dashboard Configuration
# Dashboard: Nautilus Trading Overview
{
  "dashboard": {
    "title": "Nautilus Trading Platform Overview",
    "panels": [
      {
        "title": "System Health",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=\"nautilus-backend\"}",
            "legendFormat": "Backend Status"
          }
        ]
      },
      {
        "title": "API Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th Percentile"
          }
        ]
      },
      {
        "title": "Trading Volume",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(trading_volume_total[5m])",
            "legendFormat": "Trading Volume"
          }
        ]
      },
      {
        "title": "P&L Tracking",
        "type": "graph",
        "targets": [
          {
            "expr": "trading_pnl_total",
            "legendFormat": "Total P&L"
          }
        ]
      }
    ]
  }
}