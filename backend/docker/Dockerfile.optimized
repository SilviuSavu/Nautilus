# General M4 Max Optimized Dockerfile
# Comprehensive optimization for Apple M4 Max chip performance

FROM --platform=linux/arm64/v8 python:3.13-slim

# Metadata
LABEL maintainer="Nautilus Trading Platform"
LABEL description="M4 Max optimized container for maximum performance"
LABEL version="1.0.0"
LABEL architecture="arm64"
LABEL optimization.level="maximum"
LABEL target.chip="Apple M4 Max"

# Build arguments
ARG BUILD_TYPE=release
ARG OPTIMIZATION_LEVEL=O3
ARG ENABLE_LTO=true
ARG PARALLEL_JOBS=12

# Environment variables for M4 Max optimization
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONOPTIMIZE=2 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Apple Silicon and M4 Max specific optimizations
ENV ARM64_OPTIMIZATIONS=1 \
    APPLE_SILICON_NATIVE=1 \
    M4_MAX_OPTIMIZED=1 \
    UNIFIED_MEMORY_OPTIMIZATION=1

# CPU optimization settings
ENV OMP_NUM_THREADS=12 \
    MKL_NUM_THREADS=12 \
    OPENBLAS_NUM_THREADS=12 \
    VECLIB_MAXIMUM_THREADS=12 \
    BLAS_NUM_THREADS=12 \
    LAPACK_NUM_THREADS=12

# Apple Accelerate Framework optimizations
ENV ACCELERATE_NEW_LAPACK=1 \
    ACCELERATE_LAPACK_ILP64=1 \
    VECLIB_MAXIMUM_THREADS=12 \
    BNNS_ENABLED=1

# Memory optimization
ENV MALLOC_ARENA_MAX=4 \
    MALLOC_MMAP_THRESHOLD=65536 \
    MALLOC_TOP_PAD=131072 \
    PYTHONMALLOC=malloc

# Compiler optimization flags
ENV CFLAGS="-O3 -march=armv8.4-a -mtune=apple-m1 -mcpu=apple-m1 -flto -ffast-math" \
    CXXFLAGS="-O3 -march=armv8.4-a -mtune=apple-m1 -mcpu=apple-m1 -flto -ffast-math" \
    LDFLAGS="-flto -Wl,-dead_strip"

# Install optimized system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    # Build tools optimized for ARM64
    build-essential \
    cmake \
    ninja-build \
    ccache \
    # Version control and utilities
    git \
    curl \
    wget \
    pkg-config \
    # Development libraries
    libffi-dev \
    libssl-dev \
    libxml2-dev \
    libxslt1-dev \
    libjpeg-dev \
    libpng-dev \
    zlib1g-dev \
    # Linear algebra and scientific computing
    libblas-dev \
    liblapack-dev \
    libatlas-base-dev \
    libopenblas-dev \
    # Compression libraries
    liblz4-dev \
    libzstd-dev \
    libbz2-dev \
    # Database clients
    libpq-dev \
    # Performance profiling tools
    perf-tools-unstable \
    linux-perf \
    htop \
    iotop \
    # Development and debugging
    gdb \
    valgrind \
    strace \
    # Networking
    netcat-openbsd \
    net-tools \
    # Clean up
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/* \
    && rm -rf /tmp/* \
    && rm -rf /var/tmp/*

# Configure ccache for faster builds
ENV CCACHE_DIR=/tmp/ccache
ENV PATH="/usr/lib/ccache:$PATH"
RUN mkdir -p /tmp/ccache && \
    ccache --max-size=2G && \
    ccache --set-config=compression=true

# Upgrade pip with ARM64 optimizations
RUN python -m pip install --upgrade pip setuptools wheel \
    --index-url https://pypi.org/simple/ \
    --trusted-host pypi.org

# Install optimized numerical computing stack
RUN pip install --no-cache-dir \
    # Core scientific computing (optimized builds)
    numpy==1.26.* \
    scipy==1.12.* \
    pandas==2.2.* \
    # Parallel processing optimized for M4 Max
    polars==0.20.* \
    pyarrow==15.0.* \
    # Fast mathematical libraries
    numba==0.59.* \
    llvmlite==0.42.* \
    # Optimized data structures
    orjson==3.9.* \
    msgpack==1.0.* \
    # Memory mapping and efficient I/O
    mmap==1.0.* \
    h5py==3.10.* \
    # Caching and serialization
    pickle5==0.0.12 \
    joblib==1.3.*

# Install machine learning frameworks with M4 Max optimizations
RUN pip install --no-cache-dir \
    # PyTorch with Metal Performance Shaders
    torch==2.2.* \
    torchvision==0.17.* \
    torchaudio==2.2.* \
    # TensorFlow with Metal support
    tensorflow-macos==2.15.* \
    tensorflow-metal==1.1.* \
    # Scikit-learn with optimized BLAS
    scikit-learn==1.4.* \
    # Gradient boosting with native ARM64
    xgboost==2.0.* \
    lightgbm==4.3.* \
    catboost==1.2.* \
    # Deep learning utilities
    transformers==4.37.* \
    datasets==2.16.* \
    tokenizers==0.15.*

# Install Apple-specific optimization libraries
RUN pip install --no-cache-dir \
    # Apple MLX framework for M-series
    mlx==0.12.* \
    mlx-lm==0.8.* \
    # Core ML tools
    coremltools==7.2.* \
    # ONNX runtime with optimizations
    onnxruntime==1.17.* \
    # Model optimization
    optimum==1.17.*

# Install high-performance networking and async libraries
RUN pip install --no-cache-dir \
    # High-performance event loop
    uvloop==0.19.* \
    # Fast HTTP client/server
    httpx==0.26.* \
    aiohttp==3.9.* \
    # Optimized database drivers
    asyncpg==0.29.* \
    aioredis==2.0.* \
    # WebSocket optimization
    websockets==12.0.* \
    # Fast serialization
    cloudpickle==3.0.*

# Install trading and financial libraries
RUN pip install --no-cache-dir \
    # Financial data sources
    yfinance==0.2.* \
    alpha-vantage==2.3.* \
    fredapi==0.5.* \
    # Technical analysis
    pandas-ta==0.3.* \
    ta-lib==0.4.* \
    # Portfolio optimization
    cvxpy==1.4.* \
    quantlib==1.33 \
    # Time series analysis
    arch==6.3.* \
    statsmodels==0.14.* \
    # Risk management
    pyfolio==0.9.* \
    empyrical==0.5.*

# Install development and monitoring tools
RUN pip install --no-cache-dir \
    # Testing framework
    pytest==7.4.* \
    pytest-asyncio==0.23.* \
    pytest-benchmark==4.0.* \
    # Code quality
    black==24.1.* \
    isort==5.13.* \
    flake8==7.0.* \
    # Monitoring and metrics
    prometheus-client==0.19.* \
    psutil==5.9.* \
    # Logging
    structlog==24.1.* \
    # Configuration
    pydantic==2.5.*

# Create optimized directory structure
RUN mkdir -p /app/{src,data,cache,models,logs,config,tmp} \
    && mkdir -p /app/.cache/{pip,numpy,numba,torch,transformers} \
    && mkdir -p /tmp/{build-cache,runtime-cache} \
    && mkdir -p /var/log/nautilus

# Performance optimization scripts
COPY --chown=root:root <<EOF /app/m4max_optimizer.py
#!/usr/bin/env python3
"""M4 Max Performance Optimizer"""

import os
import sys
import platform
import subprocess
import psutil
from typing import Dict, List, Any, Optional

class M4MaxOptimizer:
    """Optimize system settings for M4 Max performance"""
    
    def __init__(self):
        self.cpu_count = psutil.cpu_count(logical=False)
        self.logical_cpu_count = psutil.cpu_count(logical=True)
        self.memory_gb = psutil.virtual_memory().total // (1024**3)
    
    def check_system_info(self) -> Dict[str, Any]:
        """Get comprehensive system information"""
        info = {
            "platform": platform.platform(),
            "machine": platform.machine(),
            "processor": platform.processor(),
            "python_version": platform.python_version(),
            "cpu_count_physical": self.cpu_count,
            "cpu_count_logical": self.logical_cpu_count,
            "memory_gb": self.memory_gb,
            "apple_silicon": platform.machine() == 'arm64'
        }
        
        return info
    
    def optimize_environment_variables(self) -> Dict[str, str]:
        """Set optimal environment variables for M4 Max"""
        optimizations = {}
        
        # CPU optimizations
        performance_cores = min(12, self.logical_cpu_count - 4)  # Reserve 4 cores
        optimizations.update({
            "OMP_NUM_THREADS": str(performance_cores),
            "MKL_NUM_THREADS": str(performance_cores),
            "OPENBLAS_NUM_THREADS": str(performance_cores),
            "VECLIB_MAXIMUM_THREADS": str(performance_cores),
            "NUMBA_NUM_THREADS": str(performance_cores),
            "POLARS_MAX_THREADS": str(performance_cores)
        })
        
        # Memory optimizations
        if self.memory_gb >= 32:
            optimizations.update({
                "MALLOC_ARENA_MAX": "8",
                "MALLOC_MMAP_THRESHOLD": "131072",
                "PYTHONMALLOC": "malloc"
            })
        
        # Apple-specific optimizations
        if platform.machine() == 'arm64':
            optimizations.update({
                "ACCELERATE_NEW_LAPACK": "1",
                "VECLIB_MAXIMUM_THREADS": str(performance_cores),
                "APPLE_SILICON_NATIVE": "1"
            })
        
        # Apply optimizations
        for key, value in optimizations.items():
            os.environ[key] = value
        
        return optimizations
    
    def optimize_python_runtime(self) -> Dict[str, Any]:
        """Optimize Python runtime for M4 Max"""
        optimizations = {
            "bytecode_optimization": True,
            "garbage_collection": "optimized",
            "import_caching": True
        }
        
        # Set Python optimization flags
        sys.flags.optimize = 2
        
        # Optimize garbage collection
        import gc
        gc.set_threshold(700, 10, 10)  # More aggressive GC
        
        return optimizations
    
    def check_numpy_optimization(self) -> Dict[str, Any]:
        """Check NumPy BLAS optimization"""
        try:
            import numpy as np
            config_info = np.__config__.show()
            
            # Check for optimized BLAS
            blas_info = {
                "numpy_version": np.__version__,
                "blas_optimized": "openblas" in str(config_info).lower() or 
                                "accelerate" in str(config_info).lower(),
                "config": str(config_info)
            }
            
            return blas_info
        except Exception as e:
            return {"error": str(e)}
    
    def benchmark_cpu_performance(self) -> Dict[str, float]:
        """Benchmark CPU performance"""
        import time
        import numpy as np
        
        # Matrix multiplication benchmark
        size = 2000
        a = np.random.randn(size, size).astype(np.float64)
        b = np.random.randn(size, size).astype(np.float64)
        
        # Warmup
        for _ in range(3):
            _ = np.dot(a, b)
        
        # Benchmark
        start_time = time.time()
        for _ in range(5):
            c = np.dot(a, b)
        end_time = time.time()
        
        avg_time = (end_time - start_time) / 5
        gflops = (2 * size**3) / (avg_time * 1e9)
        
        return {
            "matrix_size": f"{size}x{size}",
            "avg_time_seconds": avg_time,
            "gflops": gflops,
            "performance_rating": "excellent" if gflops > 100 else "good" if gflops > 50 else "needs_optimization"
        }
    
    def monitor_thermal_state(self) -> Dict[str, Any]:
        """Monitor thermal state (macOS specific)"""
        try:
            # This would work on macOS host
            result = subprocess.run(
                ["pmset", "-g", "therm"], 
                capture_output=True, 
                text=True, 
                timeout=5
            )
            
            if result.returncode == 0:
                return {
                    "thermal_state": "available",
                    "output": result.stdout
                }
        except (subprocess.TimeoutExpired, FileNotFoundError):
            pass
        
        return {
            "thermal_state": "not_available_in_container",
            "message": "Thermal monitoring requires host system access"
        }
    
    def generate_optimization_report(self) -> Dict[str, Any]:
        """Generate comprehensive optimization report"""
        report = {
            "timestamp": str(subprocess.check_output(["date"], text=True).strip()),
            "system_info": self.check_system_info(),
            "environment_optimizations": self.optimize_environment_variables(),
            "python_optimizations": self.optimize_python_runtime(),
            "numpy_optimization": self.check_numpy_optimization(),
            "cpu_benchmark": self.benchmark_cpu_performance(),
            "thermal_state": self.monitor_thermal_state()
        }
        
        return report

def main():
    """Run M4 Max optimization and report"""
    print("=== M4 Max Performance Optimizer ===")
    
    optimizer = M4MaxOptimizer()
    report = optimizer.generate_optimization_report()
    
    # Print key metrics
    print(f"System: {report['system_info']['machine']} ({report['system_info']['cpu_count_physical']} cores)")
    print(f"Memory: {report['system_info']['memory_gb']} GB")
    print(f"Apple Silicon: {report['system_info']['apple_silicon']}")
    
    benchmark = report['cpu_benchmark']
    print(f"CPU Performance: {benchmark['gflops']:.1f} GFLOPS ({benchmark['performance_rating']})")
    
    numpy_info = report['numpy_optimization']
    print(f"NumPy BLAS Optimized: {numpy_info.get('blas_optimized', 'unknown')}")
    
    print("\n✅ M4 Max optimizations applied successfully")
    
    return report

if __name__ == "__main__":
    main()
EOF

# Performance monitoring script
COPY --chown=root:root <<EOF /app/performance_monitor.py
#!/usr/bin/env python3
"""Real-time Performance Monitor for M4 Max"""

import time
import json
import psutil
from typing import Dict, List, Any
from datetime import datetime

class PerformanceMonitor:
    """Monitor system performance in real-time"""
    
    def __init__(self, interval: float = 1.0):
        self.interval = interval
        self.metrics_history = []
    
    def collect_system_metrics(self) -> Dict[str, Any]:
        """Collect comprehensive system metrics"""
        timestamp = datetime.now().isoformat()
        
        # CPU metrics
        cpu_percent = psutil.cpu_percent(interval=None, percpu=True)
        cpu_freq = psutil.cpu_freq()
        
        # Memory metrics
        memory = psutil.virtual_memory()
        swap = psutil.swap_memory()
        
        # Disk I/O metrics
        disk_io = psutil.disk_io_counters()
        
        # Network metrics
        network_io = psutil.net_io_counters()
        
        metrics = {
            "timestamp": timestamp,
            "cpu": {
                "percent_per_core": cpu_percent,
                "percent_total": sum(cpu_percent) / len(cpu_percent),
                "frequency_mhz": cpu_freq.current if cpu_freq else None,
                "load_average": psutil.getloadavg() if hasattr(psutil, 'getloadavg') else None
            },
            "memory": {
                "total_gb": memory.total / (1024**3),
                "used_gb": memory.used / (1024**3),
                "available_gb": memory.available / (1024**3),
                "percent": memory.percent,
                "swap_used_gb": swap.used / (1024**3) if swap else 0
            },
            "disk": {
                "read_mb_per_sec": (disk_io.read_bytes / (1024**2)) if disk_io else 0,
                "write_mb_per_sec": (disk_io.write_bytes / (1024**2)) if disk_io else 0,
                "read_iops": disk_io.read_count if disk_io else 0,
                "write_iops": disk_io.write_count if disk_io else 0
            },
            "network": {
                "bytes_sent_mb": (network_io.bytes_sent / (1024**2)) if network_io else 0,
                "bytes_recv_mb": (network_io.bytes_recv / (1024**2)) if network_io else 0,
                "packets_sent": network_io.packets_sent if network_io else 0,
                "packets_recv": network_io.packets_recv if network_io else 0
            }
        }
        
        return metrics
    
    def analyze_performance_trends(self, window_size: int = 60) -> Dict[str, Any]:
        """Analyze performance trends over time"""
        if len(self.metrics_history) < window_size:
            return {"error": "Insufficient data for trend analysis"}
        
        recent_metrics = self.metrics_history[-window_size:]
        
        # Calculate averages and trends
        cpu_values = [m["cpu"]["percent_total"] for m in recent_metrics]
        memory_values = [m["memory"]["percent"] for m in recent_metrics]
        
        trends = {
            "cpu": {
                "average": sum(cpu_values) / len(cpu_values),
                "max": max(cpu_values),
                "min": min(cpu_values),
                "trend": "increasing" if cpu_values[-1] > cpu_values[0] else "decreasing"
            },
            "memory": {
                "average": sum(memory_values) / len(memory_values),
                "max": max(memory_values),
                "min": min(memory_values),
                "trend": "increasing" if memory_values[-1] > memory_values[0] else "decreasing"
            },
            "analysis_window_minutes": window_size * self.interval / 60
        }
        
        return trends
    
    def detect_performance_issues(self, metrics: Dict[str, Any]) -> List[Dict[str, str]]:
        """Detect potential performance issues"""
        issues = []
        
        # High CPU usage
        if metrics["cpu"]["percent_total"] > 90:
            issues.append({
                "type": "high_cpu_usage",
                "severity": "high",
                "message": f"CPU usage at {metrics['cpu']['percent_total']:.1f}%"
            })
        
        # High memory usage
        if metrics["memory"]["percent"] > 85:
            issues.append({
                "type": "high_memory_usage",
                "severity": "high",
                "message": f"Memory usage at {metrics['memory']['percent']:.1f}%"
            })
        
        # Memory pressure
        if metrics["memory"]["swap_used_gb"] > 1:
            issues.append({
                "type": "memory_pressure",
                "severity": "medium",
                "message": f"Swap usage at {metrics['memory']['swap_used_gb']:.1f} GB"
            })
        
        # High load average (if available)
        if metrics["cpu"].get("load_average") and metrics["cpu"]["load_average"][0] > 12:
            issues.append({
                "type": "high_load_average",
                "severity": "medium",
                "message": f"Load average: {metrics['cpu']['load_average'][0]:.2f}"
            })
        
        return issues
    
    def run_continuous_monitoring(self, duration_minutes: int = 5):
        """Run continuous performance monitoring"""
        print(f"=== Starting Performance Monitor (M4 Max) ===")
        print(f"Duration: {duration_minutes} minutes")
        print(f"Interval: {self.interval} seconds")
        print()
        
        start_time = time.time()
        end_time = start_time + (duration_minutes * 60)
        
        while time.time() < end_time:
            metrics = self.collect_system_metrics()
            self.metrics_history.append(metrics)
            
            # Detect issues
            issues = self.detect_performance_issues(metrics)
            
            # Print current status
            cpu_pct = metrics["cpu"]["percent_total"]
            mem_pct = metrics["memory"]["percent"]
            mem_gb = metrics["memory"]["used_gb"]
            
            print(f"CPU: {cpu_pct:5.1f}% | Memory: {mem_pct:5.1f}% ({mem_gb:.1f}GB) | Issues: {len(issues)}")
            
            if issues:
                for issue in issues:
                    print(f"  ⚠ {issue['message']}")
            
            time.sleep(self.interval)
        
        print(f"\n=== Monitoring Complete ===")
        print(f"Collected {len(self.metrics_history)} data points")
        
        # Generate summary
        if len(self.metrics_history) > 10:
            trends = self.analyze_performance_trends()
            print(f"Average CPU: {trends['cpu']['average']:.1f}%")
            print(f"Average Memory: {trends['memory']['average']:.1f}%")

def main():
    """Main performance monitoring function"""
    monitor = PerformanceMonitor(interval=1.0)
    
    # Run for 5 minutes by default
    monitor.run_continuous_monitoring(duration_minutes=5)

if __name__ == "__main__":
    main()
EOF

# Make all scripts executable
RUN chmod +x /app/m4max_optimizer.py /app/performance_monitor.py

# Set working directory
WORKDIR /app

# Create non-root user with optimized settings
RUN groupadd -r nautilus && \
    useradd -r -g nautilus -s /bin/bash nautilus && \
    # Set CPU affinity preferences (will be overridden by Docker)
    echo "nautilus soft nofile 65536" >> /etc/security/limits.conf && \
    echo "nautilus hard nofile 65536" >> /etc/security/limits.conf && \
    # Set up directory permissions
    chown -R nautilus:nautilus /app && \
    chown -R nautilus:nautilus /tmp/runtime-cache

# Copy application requirements (if they exist)
COPY requirements.txt /app/ 2>/dev/null || echo "# No requirements.txt found" > /app/requirements.txt
RUN pip install --no-cache-dir -r /app/requirements.txt

# Run optimization script during build
RUN python /app/m4max_optimizer.py > /app/optimization_report.json

# Switch to non-root user
USER nautilus

# Health check with optimization verification
HEALTHCHECK --interval=30s --timeout=15s --start-period=10s --retries=3 \
    CMD python -c "import psutil; import numpy as np; print(f'Health: CPU={psutil.cpu_percent():.1f}%, Memory={psutil.virtual_memory().percent:.1f}%'); exit(0)"

# Default command runs the optimizer and stays running
CMD ["python", "/app/m4max_optimizer.py"]

# Final build labels
LABEL build.type=${BUILD_TYPE}
LABEL optimization.level=${OPTIMIZATION_LEVEL}
LABEL enable.lto=${ENABLE_LTO}
LABEL parallel.jobs=${PARALLEL_JOBS}
LABEL m4max.optimized=true
LABEL apple.accelerate=true
LABEL performance.tier=maximum