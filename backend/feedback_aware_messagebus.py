#!/usr/bin/env python3
"""
Feedback-Aware MessageBus Enhancement for Nautilus Triple MessageBus Architecture

Enhances the existing triple messagebus system with:
- Dynamic priority adjustment based on downstream latency feedback
- Automatic batch size optimization using negative feedback loops  
- Circuit breaker patterns with gradual recovery mechanisms
- Back-pressure propagation through nested control loops
- Predictive message routing using ML Engine signals
- Self-healing during market volatility via adaptive algorithms

Enhanced Bus Architecture:
- MarketData Bus (6380): Neural Engine optimized with feedback control
- Engine Logic Bus (6381): Metal GPU optimized with adaptive routing
- Neural-GPU Bus (6382): Unified memory optimized with predictive routing

Performance Target: 50k+ msg/sec with <0.5ms latency
Author: BMad Orchestrator
"""

import asyncio
import time
import logging
import threading
from typing import Dict, List, Any, Optional, Callable, Set, Tuple, NamedTuple
from enum import Enum, IntEnum
from dataclasses import dataclass, field
import json
import statistics
import numpy as np
from collections import deque, defaultdict
import heapq
import hashlib
import uuid
import redis.asyncio as redis

# Import existing messagebus components
from dual_messagebus_client import DualMessageBusClient, MessageBusType
from universal_enhanced_messagebus_client import (
    MessageType, EngineType, MessagePriority, UniversalMessage
)

logger = logging.getLogger(__name__)


class FeedbackSignalType(Enum):
    """Types of feedback signals for message bus optimization"""
    LATENCY_SPIKE = "latency_spike"
    THROUGHPUT_DROP = "throughput_drop"
    QUEUE_DEPTH_HIGH = "queue_depth_high"
    ERROR_RATE_HIGH = "error_rate_high"
    BACKPRESSURE_DETECTED = "backpressure_detected"
    CIRCUIT_OPEN = "circuit_open"
    PREDICTION_ACCURACY_LOW = "prediction_accuracy_low"


class CircuitState(Enum):
    """Circuit breaker states"""
    CLOSED = "closed"        # Normal operation
    OPEN = "open"           # Circuit tripped, blocking requests
    HALF_OPEN = "half_open" # Testing recovery with limited requests


class RoutingStrategy(Enum):
    """Message routing strategies"""
    ROUND_ROBIN = "round_robin"
    LEAST_LOADED = "least_loaded"
    PREDICTIVE = "predictive"
    LATENCY_AWARE = "latency_aware"
    FEEDBACK_OPTIMAL = "feedback_optimal"


class BackPressureLevel(IntEnum):
    """Back-pressure intensity levels"""
    NONE = 0
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4


@dataclass
class MessageMetrics:
    """Comprehensive metrics for individual messages"""
    message_id: str
    message_type: MessageType
    source_engine: str
    target_engines: List[str]
    timestamp_sent: float
    timestamp_received: Optional[float] = None
    latency_ms: Optional[float] = None
    priority: MessagePriority = MessagePriority.NORMAL
    size_bytes: int = 0
    processing_time_ms: float = 0.0
    retry_count: int = 0
    circuit_state: CircuitState = CircuitState.CLOSED
    backpressure_level: BackPressureLevel = BackPressureLevel.NONE


@dataclass
class BusPerformanceMetrics:
    """Performance metrics for message bus"""
    bus_name: str
    throughput_msg_per_sec: float = 0.0
    average_latency_ms: float = 0.0
    p95_latency_ms: float = 0.0
    error_rate: float = 0.0
    queue_depth: int = 0
    active_circuits: int = 0
    backpressure_events: int = 0
    prediction_accuracy: float = 0.0
    
    # Historical data for trend analysis
    latency_history: deque = field(default_factory=lambda: deque(maxlen=1000))
    throughput_history: deque = field(default_factory=lambda: deque(maxlen=1000))
    error_history: deque = field(default_factory=lambda: deque(maxlen=1000))


@dataclass
class CircuitBreakerConfig:
    """Circuit breaker configuration"""
    failure_threshold: int = 10      # Failures before opening
    recovery_timeout: float = 30.0   # Seconds before half-open
    success_threshold: int = 5       # Successes to close circuit
    timeout_ms: float = 5000.0      # Request timeout
    
    # Adaptive parameters
    enable_adaptive_threshold: bool = True
    threshold_adjustment_rate: float = 0.1


class CircuitBreaker:
    """Circuit breaker with adaptive thresholds and gradual recovery"""
    
    def __init__(self, name: str, config: CircuitBreakerConfig):
        self.name = name
        self.config = config
        self.state = CircuitState.CLOSED
        
        # State tracking
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time = 0.0
        self.next_attempt_time = 0.0
        
        # Adaptive tracking
        self.recent_latencies = deque(maxlen=100)
        self.recent_error_rates = deque(maxlen=100)
        
        # Performance metrics
        self.total_requests = 0
        self.total_failures = 0
        self.total_timeouts = 0
        
        logger.debug(f"ðŸ”Œ CircuitBreaker created: {name}")
        
    async def call(self, func: Callable, *args, **kwargs) -> Tuple[Any, bool]:
        """Execute function call with circuit breaker protection"""
        
        self.total_requests += 1
        
        # Check circuit state
        if self.state == CircuitState.OPEN:
            if time.time() < self.next_attempt_time:
                # Circuit still open, reject immediately
                raise Exception(f"Circuit breaker {self.name} is OPEN")
            else:
                # Try transition to half-open
                self.state = CircuitState.HALF_OPEN
                self.success_count = 0
                logger.info(f"ðŸ”§ Circuit breaker {self.name} transitioning to HALF_OPEN")
                
        start_time = time.perf_counter()
        
        try:
            # Execute the function with timeout
            result = await asyncio.wait_for(
                func(*args, **kwargs),
                timeout=self.config.timeout_ms / 1000.0
            )
            
            # Record success
            latency = (time.perf_counter() - start_time) * 1000
            await self._record_success(latency)
            
            return result, True
            
        except asyncio.TimeoutError:
            # Record timeout
            self.total_timeouts += 1
            await self._record_failure('timeout')
            raise Exception(f"Circuit breaker {self.name} timeout")
            
        except Exception as e:
            # Record failure
            await self._record_failure('error', str(e))
            raise e
            
    async def _record_success(self, latency_ms: float):
        """Record successful operation"""
        
        self.recent_latencies.append(latency_ms)
        
        if self.state == CircuitState.HALF_OPEN:
            self.success_count += 1
            
            # Check if we can close the circuit
            if self.success_count >= self.config.success_threshold:
                self.state = CircuitState.CLOSED
                self.failure_count = 0
                logger.info(f"âœ… Circuit breaker {self.name} CLOSED after recovery")
                
        elif self.state == CircuitState.CLOSED:
            # Reduce failure count on success (gradual recovery)
            self.failure_count = max(0, self.failure_count - 1)
            
    async def _record_failure(self, failure_type: str, details: str = ""):
        """Record failed operation"""
        
        self.failure_count += 1
        self.total_failures += 1
        self.last_failure_time = time.time()
        
        # Calculate error rate
        error_rate = self.total_failures / max(self.total_requests, 1)
        self.recent_error_rates.append(error_rate)
        
        logger.warning(f"âš ï¸ Circuit breaker {self.name} failure: {failure_type} ({details})")
        
        # Adaptive threshold adjustment
        if self.config.enable_adaptive_threshold:
            await self._adjust_adaptive_threshold()
            
        # Check if we should open the circuit
        if self.failure_count >= self.config.failure_threshold:
            self.state = CircuitState.OPEN
            self.next_attempt_time = time.time() + self.config.recovery_timeout
            logger.error(f"ðŸš¨ Circuit breaker {self.name} OPENED (failures: {self.failure_count})")
            
    async def _adjust_adaptive_threshold(self):
        """Adjust failure threshold based on recent performance"""
        
        if len(self.recent_error_rates) < 10:
            return
            
        # Calculate recent error rate trend
        recent_errors = list(self.recent_error_rates)[-10:]
        avg_error_rate = statistics.mean(recent_errors)
        
        # Adjust threshold based on error rate
        if avg_error_rate > 0.1:  # High error rate
            # Lower threshold to be more sensitive
            adjustment = -self.config.threshold_adjustment_rate
        elif avg_error_rate < 0.01:  # Low error rate
            # Raise threshold to be more tolerant
            adjustment = self.config.threshold_adjustment_rate
        else:
            return  # No adjustment needed
            
        # Apply adjustment
        new_threshold = self.config.failure_threshold * (1 + adjustment)
        new_threshold = max(3, min(new_threshold, 50))  # Keep reasonable bounds
        
        if abs(new_threshold - self.config.failure_threshold) > 1:
            logger.info(f"ðŸ”§ Circuit {self.name} threshold: {self.config.failure_threshold} â†’ {new_threshold:.1f}")
            self.config.failure_threshold = int(new_threshold)
            
    def get_metrics(self) -> Dict[str, Any]:
        """Get circuit breaker metrics"""
        
        return {
            'name': self.name,
            'state': self.state.value,
            'failure_count': self.failure_count,
            'success_count': self.success_count,
            'total_requests': self.total_requests,
            'total_failures': self.total_failures,
            'total_timeouts': self.total_timeouts,
            'error_rate': self.total_failures / max(self.total_requests, 1),
            'average_latency_ms': statistics.mean(self.recent_latencies) if self.recent_latencies else 0.0,
            'config': {
                'failure_threshold': self.config.failure_threshold,
                'recovery_timeout': self.config.recovery_timeout,
                'timeout_ms': self.config.timeout_ms
            }
        }


class AdaptiveBatchProcessor:
    """Adaptive batch processing with feedback-driven optimization"""
    
    def __init__(self, initial_batch_size: int = 50):
        self.current_batch_size = initial_batch_size
        self.min_batch_size = 1
        self.max_batch_size = 1000
        
        # Performance tracking
        self.batch_performance_history = deque(maxlen=100)
        self.latency_targets = {
            MessagePriority.CRITICAL: 0.5,  # 0.5ms
            MessagePriority.HIGH: 1.0,      # 1ms
            MessagePriority.NORMAL: 2.0,    # 2ms
            MessagePriority.LOW: 5.0        # 5ms
        }
        
        # Optimization parameters
        self.adjustment_rate = 0.1
        self.performance_threshold = 0.8
        
    async def process_batch(self, messages: List[UniversalMessage], 
                          process_func: Callable) -> List[Tuple[str, bool, float]]:
        """Process message batch with adaptive sizing"""
        
        if not messages:
            return []
            
        start_time = time.perf_counter()
        batch_size = len(messages)
        
        # Group messages by priority for optimal processing
        priority_groups = defaultdict(list)
        for msg in messages:
            priority_groups[msg.priority].append(msg)
            
        results = []
        
        # Process high-priority messages first
        priority_order = [MessagePriority.CRITICAL, MessagePriority.HIGH, 
                         MessagePriority.NORMAL, MessagePriority.LOW]
                         
        for priority in priority_order:
            if priority in priority_groups:
                group_messages = priority_groups[priority]
                
                # Process this priority group
                for msg in group_messages:
                    try:
                        result = await process_func(msg)
                        processing_time = (time.perf_counter() - start_time) * 1000
                        results.append((msg.id, True, processing_time))
                        
                    except Exception as e:
                        processing_time = (time.perf_counter() - start_time) * 1000
                        results.append((msg.id, False, processing_time))
                        logger.error(f"Batch processing error: {e}")
                        
        # Record batch performance
        total_time = (time.perf_counter() - start_time) * 1000
        await self._record_batch_performance(batch_size, total_time, results)
        
        return results
        
    async def _record_batch_performance(self, batch_size: int, total_time_ms: float,
                                      results: List[Tuple[str, bool, float]]):
        """Record batch performance and adapt batch size"""
        
        success_count = sum(1 for _, success, _ in results)
        success_rate = success_count / len(results) if results else 0
        avg_message_time = total_time_ms / len(results) if results else 0
        
        performance_record = {
            'batch_size': batch_size,
            'total_time_ms': total_time_ms,
            'avg_message_time_ms': avg_message_time,
            'success_rate': success_rate,
            'throughput_msg_per_sec': (len(results) / total_time_ms * 1000) if total_time_ms > 0 else 0
        }
        
        self.batch_performance_history.append(performance_record)
        
        # Adapt batch size based on performance
        await self._adapt_batch_size(performance_record)
        
    async def _adapt_batch_size(self, current_performance: Dict[str, Any]):
        """Adapt batch size based on performance feedback"""
        
        if len(self.batch_performance_history) < 5:
            return  # Need more data
            
        # Calculate performance trend
        recent_records = list(self.batch_performance_history)[-5:]
        
        avg_throughput = statistics.mean([r['throughput_msg_per_sec'] for r in recent_records])
        avg_latency = statistics.mean([r['avg_message_time_ms'] for r in recent_records])
        avg_success_rate = statistics.mean([r['success_rate'] for r in recent_records])
        
        # Performance score (0-1, higher is better)
        throughput_score = min(avg_throughput / 10000, 1.0)  # Normalize to 10k msg/sec
        latency_score = max(0, 1.0 - (avg_latency / 10.0))    # Target <10ms
        success_score = avg_success_rate
        
        performance_score = (throughput_score * 0.4 + latency_score * 0.4 + success_score * 0.2)
        
        # Determine batch size adjustment
        if performance_score > self.performance_threshold:
            # Good performance - try increasing batch size
            if avg_latency < 2.0:  # Only if latency is acceptable
                adjustment = max(1, int(self.current_batch_size * self.adjustment_rate))
                new_batch_size = min(self.current_batch_size + adjustment, self.max_batch_size)
            else:
                new_batch_size = self.current_batch_size
        else:
            # Poor performance - decrease batch size
            adjustment = max(1, int(self.current_batch_size * self.adjustment_rate))
            new_batch_size = max(self.current_batch_size - adjustment, self.min_batch_size)
            
        # Apply batch size change
        if new_batch_size != self.current_batch_size:
            logger.info(f"ðŸ”§ Batch size adapted: {self.current_batch_size} â†’ {new_batch_size} "
                       f"(score: {performance_score:.3f})")
            self.current_batch_size = new_batch_size
            
    def get_optimal_batch_size(self, message_count: int, priority: MessagePriority) -> int:
        """Get optimal batch size for current conditions"""
        
        # Adjust based on message priority
        priority_factors = {
            MessagePriority.CRITICAL: 0.5,  # Smaller batches for critical messages
            MessagePriority.HIGH: 0.8,
            MessagePriority.NORMAL: 1.0,
            MessagePriority.LOW: 1.5       # Larger batches for low priority
        }
        
        adjusted_size = int(self.current_batch_size * priority_factors.get(priority, 1.0))
        
        # Don't exceed available messages
        return min(adjusted_size, message_count)


class PredictiveRouter:
    """ML-based predictive message routing"""
    
    def __init__(self):
        self.routing_history = deque(maxlen=10000)
        self.engine_performance = defaultdict(lambda: {'latency': deque(maxlen=100), 
                                                       'throughput': deque(maxlen=100),
                                                       'success_rate': deque(maxlen=100)})
        
        # Simple prediction model (would be replaced with actual ML)
        self.prediction_weights = defaultdict(lambda: {'latency': 1.0, 'load': 1.0, 'history': 1.0})
        
    async def predict_optimal_route(self, message: UniversalMessage, 
                                  available_targets: List[str]) -> List[str]:
        """Predict optimal routing for message"""
        
        if not available_targets:
            return []
            
        # Score each potential target
        target_scores = []
        
        for target in available_targets:
            score = await self._calculate_target_score(target, message)
            target_scores.append((target, score))
            
        # Sort by score (higher is better) and return top targets
        target_scores.sort(key=lambda x: x[1], reverse=True)
        
        # Return targets in priority order
        return [target for target, score in target_scores]
        
    async def _calculate_target_score(self, target: str, message: UniversalMessage) -> float:
        """Calculate routing score for target engine"""
        
        performance = self.engine_performance[target]
        
        # Factor 1: Latency (lower is better)
        if performance['latency']:
            avg_latency = statistics.mean(performance['latency'])
            latency_score = max(0, 1.0 - (avg_latency / 10.0))  # Normalize to 10ms
        else:
            latency_score = 0.5  # Unknown performance
            
        # Factor 2: Current load (lower is better)
        current_queue_depth = len(performance['latency'])  # Proxy for current load
        load_score = max(0, 1.0 - (current_queue_depth / 100.0))  # Normalize to 100 messages
        
        # Factor 3: Historical success rate
        if performance['success_rate']:
            success_score = statistics.mean(performance['success_rate'])
        else:
            success_score = 0.5  # Unknown
            
        # Factor 4: Message type affinity (simple heuristic)
        affinity_score = await self._calculate_affinity_score(target, message.message_type)
        
        # Weighted combination
        weights = self.prediction_weights[target]
        total_score = (
            latency_score * weights['latency'] +
            load_score * weights['load'] + 
            success_score * weights['history'] +
            affinity_score * 0.3
        ) / (weights['latency'] + weights['load'] + weights['history'] + 0.3)
        
        return total_score
        
    async def _calculate_affinity_score(self, target: str, message_type: MessageType) -> float:
        """Calculate affinity between target engine and message type"""
        
        # Simple affinity rules (would be learned from data in production)
        affinities = {
            ('analytics', MessageType.ANALYTICS_RESULT): 1.0,
            ('risk', MessageType.RISK_METRIC): 1.0,
            ('ml', MessageType.ML_PREDICTION): 1.0,
            ('strategy', MessageType.STRATEGY_SIGNAL): 1.0,
            ('portfolio', MessageType.PORTFOLIO_UPDATE): 1.0,
        }
        
        return affinities.get((target, message_type), 0.5)
        
    async def record_routing_outcome(self, target: str, message: UniversalMessage, 
                                   latency_ms: float, success: bool):
        """Record routing outcome for learning"""
        
        performance = self.engine_performance[target]
        performance['latency'].append(latency_ms)
        performance['success_rate'].append(1.0 if success else 0.0)
        
        # Store routing decision for pattern learning
        routing_record = {
            'timestamp': time.time(),
            'target': target,
            'message_type': message.message_type.value,
            'priority': message.priority.value,
            'latency_ms': latency_ms,
            'success': success
        }
        
        self.routing_history.append(routing_record)
        
        # Update prediction weights based on outcome
        await self._update_prediction_weights(target, latency_ms, success)
        
    async def _update_prediction_weights(self, target: str, latency_ms: float, success: bool):
        """Update prediction model weights based on outcomes"""
        
        weights = self.prediction_weights[target]
        
        # Simple adaptive weight adjustment
        learning_rate = 0.01
        
        if success and latency_ms < 5.0:  # Good outcome
            # Increase confidence in current weights
            weights['latency'] *= (1 + learning_rate)
            weights['load'] *= (1 + learning_rate)
            weights['history'] *= (1 + learning_rate)
        elif not success or latency_ms > 20.0:  # Poor outcome
            # Decrease confidence in current weights
            weights['latency'] *= (1 - learning_rate)
            weights['load'] *= (1 - learning_rate)
            weights['history'] *= (1 - learning_rate)
            
        # Keep weights bounded
        for key in weights:
            weights[key] = max(0.1, min(weights[key], 5.0))


class FeedbackAwareMessageBus(DualMessageBusClient):
    """
    Enhanced MessageBus with comprehensive feedback loop integration
    
    Features:
    - Dynamic priority adjustment based on downstream latency
    - Adaptive batch processing with feedback optimization
    - Circuit breaker patterns for fault tolerance
    - Back-pressure propagation through control loops
    - Predictive routing using performance feedback
    - Self-healing capabilities during market volatility
    """
    
    def __init__(self, config, feedback_controller_callback: Optional[Callable] = None):
        super().__init__(config)
        
        self.feedback_controller_callback = feedback_controller_callback
        
        # Enhanced components
        self.circuit_breakers: Dict[str, CircuitBreaker] = {}
        self.batch_processor = AdaptiveBatchProcessor()
        self.predictive_router = PredictiveRouter()
        
        # Performance tracking
        self.bus_metrics = {
            MessageBusType.MARKETDATA_BUS: BusPerformanceMetrics("marketdata_bus"),
            MessageBusType.ENGINE_LOGIC_BUS: BusPerformanceMetrics("engine_logic_bus")
        }
        
        # Message queues with priority
        self.priority_queues: Dict[MessageBusType, Dict[MessagePriority, asyncio.Queue]] = {
            MessageBusType.MARKETDATA_BUS: {
                priority: asyncio.Queue(maxsize=10000) for priority in MessagePriority
            },
            MessageBusType.ENGINE_LOGIC_BUS: {
                priority: asyncio.Queue(maxsize=10000) for priority in MessagePriority
            }
        }
        
        # Back-pressure state
        self.backpressure_levels: Dict[MessageBusType, BackPressureLevel] = {
            MessageBusType.MARKETDATA_BUS: BackPressureLevel.NONE,
            MessageBusType.ENGINE_LOGIC_BUS: BackPressureLevel.NONE
        }
        
        # Enhanced background tasks
        self._feedback_tasks: List[asyncio.Task] = []
        
        logger.info("ðŸŽ›ï¸ FeedbackAwareMessageBus initialized with advanced capabilities")
        
    async def initialize(self):
        """Initialize with feedback enhancements"""
        
        # Call parent initialization
        await super().initialize()
        
        # Initialize circuit breakers for critical paths
        self._initialize_circuit_breakers()
        
        # Start feedback-specific tasks
        await self._start_feedback_tasks()
        
        logger.info("ðŸš€ FeedbackAwareMessageBus fully operational with feedback loops")
        
    async def close(self):
        """Enhanced close with feedback cleanup"""
        
        # Stop feedback tasks
        for task in self._feedback_tasks:
            if not task.done():
                task.cancel()
                
        if self._feedback_tasks:
            await asyncio.gather(*self._feedback_tasks, return_exceptions=True)
            
        # Call parent close
        await super().close()
        
        logger.info("ðŸ›‘ FeedbackAwareMessageBus shutdown complete")
        
    async def publish_message_enhanced(self, message_type: MessageType, payload: Dict[str, Any],
                                     priority: MessagePriority = MessagePriority.NORMAL,
                                     correlation_id: Optional[str] = None,
                                     target_engines: Optional[List[str]] = None) -> bool:
        """Enhanced message publishing with feedback optimization"""
        
        # Create enhanced message with metadata
        message = UniversalMessage(
            id=correlation_id or str(uuid.uuid4()),
            message_type=message_type,
            source=self.config.engine_type.value,
            priority=priority,
            payload=payload,
            timestamp=time.time_ns(),
            target_engines=target_engines or []
        )
        
        # Select bus and apply feedback optimizations
        redis_client, bus_type = self._select_bus(message_type)
        
        # Check backpressure
        if await self._should_apply_backpressure(bus_type, priority):
            await self._handle_backpressure(bus_type, message)
            return False
            
        # Predictive routing if targets not specified
        if not message.target_engines and bus_type == MessageBusType.ENGINE_LOGIC_BUS:
            available_engines = await self._get_available_engines()
            message.target_engines = await self.predictive_router.predict_optimal_route(
                message, available_engines
            )
            
        # Add to priority queue
        priority_queue = self.priority_queues[bus_type][priority]
        
        try:
            await priority_queue.put(message)
            
            # Update metrics
            metrics = self.bus_metrics[bus_type]
            metrics.queue_depth = priority_queue.qsize()
            
            return True
            
        except asyncio.QueueFull:
            # Handle queue overflow with back-pressure
            await self._trigger_backpressure(bus_type, BackPressureLevel.HIGH)
            return False
            
    async def _should_apply_backpressure(self, bus_type: MessageBusType, 
                                       priority: MessagePriority) -> bool:
        """Determine if back-pressure should be applied"""
        
        backpressure_level = self.backpressure_levels[bus_type]
        
        # Never apply back-pressure to critical messages
        if priority == MessagePriority.CRITICAL:
            return False
            
        # Apply back-pressure based on level and priority
        if backpressure_level == BackPressureLevel.CRITICAL:
            return priority != MessagePriority.HIGH
        elif backpressure_level == BackPressureLevel.HIGH:
            return priority == MessagePriority.LOW
        elif backpressure_level == BackPressureLevel.MEDIUM:
            return priority == MessagePriority.LOW and np.random.random() < 0.5
            
        return False
        
    async def _handle_backpressure(self, bus_type: MessageBusType, message: UniversalMessage):
        """Handle back-pressure situation"""
        
        logger.warning(f"âš ï¸ Back-pressure applied to {bus_type.value}: {message.message_type.value}")
        
        # Update metrics
        metrics = self.bus_metrics[bus_type]
        metrics.backpressure_events += 1
        
        # Notify feedback controller if available
        if self.feedback_controller_callback:
            await self.feedback_controller_callback({
                'event_type': 'backpressure_applied',
                'bus_type': bus_type.value,
                'message_type': message.message_type.value,
                'priority': message.priority.value,
                'level': self.backpressure_levels[bus_type].name
            })
            
    async def _trigger_backpressure(self, bus_type: MessageBusType, level: BackPressureLevel):
        """Trigger back-pressure at specified level"""
        
        current_level = self.backpressure_levels[bus_type]
        
        if level > current_level:
            self.backpressure_levels[bus_type] = level
            
            logger.warning(f"ðŸ”´ Back-pressure escalated on {bus_type.value}: {level.name}")
            
            # Notify feedback controller
            if self.feedback_controller_callback:
                await self.feedback_controller_callback({
                    'event_type': 'backpressure_escalated',
                    'bus_type': bus_type.value,
                    'old_level': current_level.name,
                    'new_level': level.name
                })
                
    def _initialize_circuit_breakers(self):
        """Initialize circuit breakers for critical message paths"""
        
        # Circuit breaker configs for different message types
        configs = {
            'critical_messages': CircuitBreakerConfig(
                failure_threshold=5,
                recovery_timeout=10.0,
                timeout_ms=1000.0
            ),
            'high_priority': CircuitBreakerConfig(
                failure_threshold=10,
                recovery_timeout=30.0,
                timeout_ms=5000.0
            ),
            'normal_priority': CircuitBreakerConfig(
                failure_threshold=20,
                recovery_timeout=60.0,
                timeout_ms=10000.0
            )
        }
        
        for name, config in configs.items():
            self.circuit_breakers[name] = CircuitBreaker(name, config)
            
        logger.info(f"ðŸ”Œ Initialized {len(self.circuit_breakers)} circuit breakers")
        
    async def _start_feedback_tasks(self):
        """Start feedback-specific background tasks"""
        
        tasks = [
            self._priority_queue_processor_task(),
            self._performance_monitor_task(),
            self._backpressure_management_task(),
            self._circuit_breaker_monitor_task(),
            self._predictive_optimization_task()
        ]
        
        self._feedback_tasks = [asyncio.create_task(task) for task in tasks]
        
        logger.info(f"ðŸ”„ Started {len(self._feedback_tasks)} feedback optimization tasks")
        
    async def _priority_queue_processor_task(self):
        """Process messages from priority queues with adaptive batching"""
        
        while self._running:
            try:
                for bus_type, priority_queues in self.priority_queues.items():
                    
                    # Process queues in priority order
                    for priority in [MessagePriority.CRITICAL, MessagePriority.HIGH, 
                                   MessagePriority.NORMAL, MessagePriority.LOW]:
                        
                        queue = priority_queues[priority]
                        
                        if not queue.empty():
                            # Collect batch of messages
                            batch_size = self.batch_processor.get_optimal_batch_size(
                                queue.qsize(), priority
                            )
                            
                            messages = []
                            for _ in range(min(batch_size, queue.qsize())):
                                try:
                                    message = await asyncio.wait_for(queue.get(), timeout=0.1)
                                    messages.append(message)
                                except asyncio.TimeoutError:
                                    break
                                    
                            if messages:
                                await self._process_message_batch(bus_type, messages)
                                
                await asyncio.sleep(0.001)  # 1ms between iterations
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Priority queue processor error: {e}")
                await asyncio.sleep(1)
                
    async def _process_message_batch(self, bus_type: MessageBusType, 
                                   messages: List[UniversalMessage]):
        """Process batch of messages with circuit breaker protection"""
        
        async def send_message(message: UniversalMessage) -> bool:
            """Send individual message with error handling"""
            
            try:
                # Get appropriate circuit breaker
                circuit_name = self._get_circuit_breaker_name(message.priority)
                circuit = self.circuit_breakers[circuit_name]
                
                # Execute with circuit breaker protection
                redis_client = (self.marketdata_client if bus_type == MessageBusType.MARKETDATA_BUS 
                               else self.engine_logic_client)
                
                stream_key = self._get_stream_key(message.message_type, bus_type)
                
                # Send message through circuit breaker
                await circuit.call(self._send_message_to_redis, redis_client, stream_key, message)
                
                return True
                
            except Exception as e:
                logger.error(f"Message send failed: {e}")
                return False
                
        # Process batch
        results = await self.batch_processor.process_batch(messages, send_message)
        
        # Update performance metrics
        await self._update_bus_metrics(bus_type, messages, results)
        
        # Record routing outcomes for prediction
        for i, (message_id, success, latency) in enumerate(results):
            message = messages[i]
            for target in message.target_engines:
                await self.predictive_router.record_routing_outcome(
                    target, message, latency, success
                )
                
    async def _send_message_to_redis(self, redis_client: redis.Redis, 
                                   stream_key: str, message: UniversalMessage):
        """Send message to Redis stream"""
        
        message_data = {
            "id": message.id,
            "message_type": message.message_type.value,
            "source_engine": message.source,
            "priority": message.priority.value,
            "payload": json.dumps(message.payload),
            "timestamp": message.timestamp,
            "target_engines": json.dumps(message.target_engines),
            "correlation_id": message.correlation_id or ""
        }
        
        await redis_client.xadd(stream_key, message_data, maxlen=100000)
        
    def _get_circuit_breaker_name(self, priority: MessagePriority) -> str:
        """Get appropriate circuit breaker name for priority"""
        
        if priority == MessagePriority.CRITICAL:
            return 'critical_messages'
        elif priority == MessagePriority.HIGH:
            return 'high_priority'
        else:
            return 'normal_priority'
            
    async def _update_bus_metrics(self, bus_type: MessageBusType, 
                                messages: List[UniversalMessage], 
                                results: List[Tuple[str, bool, float]]):
        """Update bus performance metrics"""
        
        metrics = self.bus_metrics[bus_type]
        current_time = time.time()
        
        # Calculate metrics from results
        successful_messages = sum(1 for _, success, _ in results)
        total_messages = len(results)
        
        if total_messages > 0:
            success_rate = successful_messages / total_messages
            avg_latency = statistics.mean([latency for _, _, latency in results])
            
            # Update throughput (messages per second)
            if results:
                time_span = max(0.001, results[-1][2] - results[0][2])  # Avoid division by zero
                throughput = total_messages / (time_span / 1000.0)
            else:
                throughput = 0.0
                
            # Update metrics
            metrics.throughput_msg_per_sec = throughput
            metrics.average_latency_ms = avg_latency
            metrics.error_rate = 1.0 - success_rate
            
            # Update history
            metrics.latency_history.append(avg_latency)
            metrics.throughput_history.append(throughput)
            metrics.error_history.append(metrics.error_rate)
            
            # Calculate P95 latency
            if len(metrics.latency_history) > 10:
                sorted_latencies = sorted(list(metrics.latency_history)[-100:])
                metrics.p95_latency_ms = sorted_latencies[int(0.95 * len(sorted_latencies))]
                
    async def _performance_monitor_task(self):
        """Monitor performance and trigger feedback"""
        
        while self._running:
            try:
                await asyncio.sleep(10)  # Monitor every 10 seconds
                
                for bus_type, metrics in self.bus_metrics.items():
                    
                    # Check for performance issues
                    if metrics.average_latency_ms > 10.0:  # High latency
                        await self._trigger_feedback_signal(
                            FeedbackSignalType.LATENCY_SPIKE,
                            bus_type,
                            metrics.average_latency_ms
                        )
                        
                    if metrics.throughput_msg_per_sec < 1000:  # Low throughput
                        await self._trigger_feedback_signal(
                            FeedbackSignalType.THROUGHPUT_DROP,
                            bus_type,
                            metrics.throughput_msg_per_sec
                        )
                        
                    if metrics.error_rate > 0.05:  # High error rate (>5%)
                        await self._trigger_feedback_signal(
                            FeedbackSignalType.ERROR_RATE_HIGH,
                            bus_type,
                            metrics.error_rate
                        )
                        
                    if metrics.queue_depth > 1000:  # High queue depth
                        await self._trigger_feedback_signal(
                            FeedbackSignalType.QUEUE_DEPTH_HIGH,
                            bus_type,
                            metrics.queue_depth
                        )
                        
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Performance monitor error: {e}")
                
    async def _trigger_feedback_signal(self, signal_type: FeedbackSignalType,
                                     bus_type: MessageBusType, value: float):
        """Trigger feedback signal to controller"""
        
        if self.feedback_controller_callback:
            feedback_data = {
                'signal_type': signal_type.value,
                'bus_type': bus_type.value,
                'value': value,
                'timestamp': time.time(),
                'bus_metrics': {
                    'throughput': self.bus_metrics[bus_type].throughput_msg_per_sec,
                    'latency': self.bus_metrics[bus_type].average_latency_ms,
                    'error_rate': self.bus_metrics[bus_type].error_rate,
                    'queue_depth': self.bus_metrics[bus_type].queue_depth
                }
            }
            
            await self.feedback_controller_callback(feedback_data)
            
    async def _backpressure_management_task(self):
        """Manage back-pressure levels based on system state"""
        
        while self._running:
            try:
                await asyncio.sleep(5)  # Check every 5 seconds
                
                for bus_type in self.backpressure_levels:
                    current_level = self.backpressure_levels[bus_type]
                    metrics = self.bus_metrics[bus_type]
                    
                    # Calculate system stress indicators
                    queue_stress = metrics.queue_depth / 1000.0  # Normalize to 1000 messages
                    latency_stress = metrics.average_latency_ms / 10.0  # Normalize to 10ms
                    error_stress = metrics.error_rate * 20.0  # Amplify error rate
                    
                    overall_stress = max(queue_stress, latency_stress, error_stress)
                    
                    # Determine appropriate back-pressure level
                    if overall_stress > 4.0:
                        target_level = BackPressureLevel.CRITICAL
                    elif overall_stress > 3.0:
                        target_level = BackPressureLevel.HIGH
                    elif overall_stress > 2.0:
                        target_level = BackPressureLevel.MEDIUM
                    elif overall_stress > 1.0:
                        target_level = BackPressureLevel.LOW
                    else:
                        target_level = BackPressureLevel.NONE
                        
                    # Adjust back-pressure level gradually
                    if target_level > current_level:
                        # Escalate immediately
                        self.backpressure_levels[bus_type] = target_level
                    elif target_level < current_level:
                        # De-escalate gradually (one level at a time)
                        new_level = BackPressureLevel(max(current_level.value - 1, target_level.value))
                        self.backpressure_levels[bus_type] = new_level
                        
                    # Log significant changes
                    if self.backpressure_levels[bus_type] != current_level:
                        logger.info(f"ðŸ”„ Back-pressure adjusted on {bus_type.value}: "
                                  f"{current_level.name} â†’ {self.backpressure_levels[bus_type].name}")
                        
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Back-pressure management error: {e}")
                
    async def _circuit_breaker_monitor_task(self):
        """Monitor and report circuit breaker states"""
        
        while self._running:
            try:
                await asyncio.sleep(30)  # Check every 30 seconds
                
                # Count circuit states
                open_circuits = sum(1 for cb in self.circuit_breakers.values() 
                                  if cb.state == CircuitState.OPEN)
                half_open_circuits = sum(1 for cb in self.circuit_breakers.values() 
                                       if cb.state == CircuitState.HALF_OPEN)
                
                # Update metrics
                for metrics in self.bus_metrics.values():
                    metrics.active_circuits = open_circuits + half_open_circuits
                    
                # Log circuit breaker status if any are open
                if open_circuits > 0 or half_open_circuits > 0:
                    logger.warning(f"ðŸ”Œ Circuit breaker status: {open_circuits} open, {half_open_circuits} half-open")
                    
                    # Trigger feedback if too many circuits are open
                    if open_circuits > 2:
                        for bus_type in self.bus_metrics:
                            await self._trigger_feedback_signal(
                                FeedbackSignalType.CIRCUIT_OPEN,
                                bus_type,
                                open_circuits
                            )
                            
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Circuit breaker monitor error: {e}")
                
    async def _predictive_optimization_task(self):
        """Perform predictive optimizations based on patterns"""
        
        while self._running:
            try:
                await asyncio.sleep(60)  # Optimize every minute
                
                # Analyze routing performance
                await self._analyze_routing_patterns()
                
                # Optimize batch sizes
                await self._optimize_batch_processing()
                
                # Predict and prevent issues
                await self._predict_performance_issues()
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Predictive optimization error: {e}")
                
    async def _analyze_routing_patterns(self):
        """Analyze routing patterns and update predictions"""
        
        if len(self.predictive_router.routing_history) < 100:
            return
            
        # Analyze recent routing decisions
        recent_routes = list(self.predictive_router.routing_history)[-100:]
        
        # Group by target engine
        target_performance = defaultdict(list)
        for route in recent_routes:
            target_performance[route['target']].append({
                'latency': route['latency_ms'],
                'success': route['success']
            })
            
        # Calculate prediction accuracy
        total_predictions = 0
        accurate_predictions = 0
        
        for target, performances in target_performance.items():
            if len(performances) > 10:
                avg_latency = statistics.mean([p['latency'] for p in performances])
                success_rate = statistics.mean([1 if p['success'] else 0 for p in performances])
                
                # Simple accuracy heuristic
                if avg_latency < 5.0 and success_rate > 0.95:
                    accurate_predictions += len(performances)
                    
                total_predictions += len(performances)
                
        # Update prediction accuracy metric
        if total_predictions > 0:
            accuracy = accurate_predictions / total_predictions
            for metrics in self.bus_metrics.values():
                metrics.prediction_accuracy = accuracy
                
            if accuracy < 0.8:
                logger.warning(f"ðŸ“‰ Low prediction accuracy: {accuracy:.1%}")
                
    async def _optimize_batch_processing(self):
        """Optimize batch processing parameters"""
        
        if len(self.batch_processor.batch_performance_history) < 10:
            return
            
        # Analyze batch performance trends
        recent_performance = list(self.batch_processor.batch_performance_history)[-10:]
        
        avg_throughput = statistics.mean([p['throughput_msg_per_sec'] for p in recent_performance])
        avg_latency = statistics.mean([p['avg_message_time_ms'] for p in recent_performance])
        
        logger.debug(f"ðŸ“Š Batch performance: {avg_throughput:.0f} msg/sec, {avg_latency:.2f}ms avg latency")
        
        # Trigger feedback if performance is poor
        if avg_throughput < 1000 or avg_latency > 10.0:
            for bus_type in self.bus_metrics:
                await self._trigger_feedback_signal(
                    FeedbackSignalType.THROUGHPUT_DROP,
                    bus_type,
                    avg_throughput
                )
                
    async def _predict_performance_issues(self):
        """Predict potential performance issues"""
        
        for bus_type, metrics in self.bus_metrics.items():
            
            # Analyze trends in latency and throughput
            if len(metrics.latency_history) > 20:
                recent_latencies = list(metrics.latency_history)[-20:]
                
                # Check for increasing latency trend
                if len(recent_latencies) >= 10:
                    first_half = recent_latencies[:10]
                    second_half = recent_latencies[10:]
                    
                    first_avg = statistics.mean(first_half)
                    second_avg = statistics.mean(second_half)
                    
                    if second_avg > first_avg * 1.5:  # 50% increase
                        logger.warning(f"ðŸ“ˆ Predicted latency spike on {bus_type.value}")
                        
                        # Pre-emptively reduce batch sizes
                        self.batch_processor.current_batch_size = max(
                            self.batch_processor.current_batch_size // 2,
                            self.batch_processor.min_batch_size
                        )
                        
    async def _get_available_engines(self) -> List[str]:
        """Get list of available target engines"""
        
        # In production, this would query actual engine availability
        # For now, return static list based on engine types
        return [
            'analytics', 'risk', 'ml', 'strategy', 'portfolio', 
            'factor', 'vpin', 'collateral', 'features'
        ]
        
    async def get_enhanced_stats(self) -> Dict[str, Any]:
        """Get comprehensive enhanced statistics"""
        
        # Get base stats
        base_stats = await super().get_stats()
        
        # Add enhanced metrics
        enhanced_stats = {
            **base_stats,
            'feedback_enhancements': {
                'bus_metrics': {
                    bus_type.value: {
                        'throughput_msg_per_sec': metrics.throughput_msg_per_sec,
                        'average_latency_ms': metrics.average_latency_ms,
                        'p95_latency_ms': metrics.p95_latency_ms,
                        'error_rate': metrics.error_rate,
                        'queue_depth': metrics.queue_depth,
                        'backpressure_events': metrics.backpressure_events,
                        'prediction_accuracy': metrics.prediction_accuracy
                    }
                    for bus_type, metrics in self.bus_metrics.items()
                },
                'circuit_breakers': {
                    name: breaker.get_metrics()
                    for name, breaker in self.circuit_breakers.items()
                },
                'batch_processor': {
                    'current_batch_size': self.batch_processor.current_batch_size,
                    'performance_records': len(self.batch_processor.batch_performance_history)
                },
                'predictive_router': {
                    'routing_records': len(self.predictive_router.routing_history),
                    'engine_count': len(self.predictive_router.engine_performance)
                },
                'backpressure_levels': {
                    bus_type.value: level.name
                    for bus_type, level in self.backpressure_levels.items()
                }
            }
        }
        
        return enhanced_stats


# Factory function for easy instantiation
def create_feedback_aware_messagebus(engine_type: EngineType, 
                                    feedback_controller_callback: Optional[Callable] = None) -> FeedbackAwareMessageBus:
    """Create feedback-aware message bus client"""
    
    from dual_messagebus_client import DualBusConfig
    
    config = DualBusConfig(
        engine_type=engine_type,
        engine_instance_id=f"{engine_type.value}-feedback-{int(time.time() * 1000) % 10000}"
    )
    
    return FeedbackAwareMessageBus(config, feedback_controller_callback)


if __name__ == "__main__":
    # Test the feedback-aware message bus
    async def test_feedback_messagebus():
        print("ðŸ§ª Testing Feedback-Aware MessageBus Enhancement")
        print("=" * 80)
        
        # Create feedback-aware message bus
        messagebus = create_feedback_aware_messagebus(EngineType.ANALYTICS)
        
        try:
            await messagebus.initialize()
            
            # Test enhanced message publishing
            test_messages = [
                (MessageType.ANALYTICS_RESULT, {'result': 'test_1'}, MessagePriority.HIGH),
                (MessageType.RISK_METRIC, {'risk': 0.05}, MessagePriority.CRITICAL),
                (MessageType.ML_PREDICTION, {'prediction': 150.0}, MessagePriority.NORMAL),
            ]
            
            print("\nðŸ“¤ Testing enhanced message publishing...")
            
            for msg_type, payload, priority in test_messages:
                success = await messagebus.publish_message_enhanced(
                    msg_type, payload, priority, target_engines=['risk', 'strategy']
                )
                print(f"   {'âœ…' if success else 'âŒ'} {msg_type.value} ({priority.value})")
                
            # Let the system process for a bit
            await asyncio.sleep(2)
            
            # Get enhanced statistics
            print("\nðŸ“Š Enhanced Statistics:")
            stats = await messagebus.get_enhanced_stats()
            
            enhancements = stats.get('feedback_enhancements', {})
            
            # Bus metrics
            for bus_name, bus_metrics in enhancements.get('bus_metrics', {}).items():
                print(f"   {bus_name}:")
                print(f"     Throughput: {bus_metrics['throughput_msg_per_sec']:.0f} msg/sec")
                print(f"     Avg Latency: {bus_metrics['average_latency_ms']:.2f}ms")
                print(f"     Error Rate: {bus_metrics['error_rate']:.1%}")
                print(f"     Queue Depth: {bus_metrics['queue_depth']}")
                
            # Circuit breakers
            circuit_breakers = enhancements.get('circuit_breakers', {})
            print(f"   Circuit Breakers: {len(circuit_breakers)} active")
            
            for name, cb_metrics in circuit_breakers.items():
                if cb_metrics['total_requests'] > 0:
                    print(f"     {name}: {cb_metrics['state']} "
                         f"({cb_metrics['total_requests']} requests, "
                         f"{cb_metrics['error_rate']:.1%} error rate)")
                         
            # Batch processing
            batch_info = enhancements.get('batch_processor', {})
            print(f"   Batch Size: {batch_info['current_batch_size']}")
            
            # Back-pressure
            backpressure = enhancements.get('backpressure_levels', {})
            print(f"   Back-pressure: {backpressure}")
            
        finally:
            await messagebus.close()
    
    asyncio.run(test_feedback_messagebus())