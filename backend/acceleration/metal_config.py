"""
Metal GPU Acceleration Configuration System for M4 Max

Provides Metal Performance Shaders (MPS) backend configuration for:
- M4 Max GPU capability detection and optimization
- PyTorch MPS backend configuration with automatic fallbacks
- Memory management optimized for 546GB/s unified memory
- Device management and thermal monitoring
- Performance profiling and optimization recommendations

Optimized for Apple Silicon M4 Max with 40 GPU cores.
"""

import asyncio
import logging
import platform
import subprocess
import time
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple, Any, Union
from contextlib import contextmanager
import threading
import psutil
import sys
import os

# Metal-specific imports with fallback handling
try:
    import torch
    import torch.backends.mps as mps
    MPS_AVAILABLE = torch.backends.mps.is_available() if hasattr(torch.backends.mps, 'is_available') else False
    MPS_BUILT = torch.backends.mps.is_built() if hasattr(torch.backends.mps, 'is_built') else False
except ImportError:
    torch = None
    mps = None
    MPS_AVAILABLE = False
    MPS_BUILT = False

try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    np = None
    NUMPY_AVAILABLE = False

try:
    # MLX framework for Apple Silicon optimization
    import mlx.core as mx
    import mlx.nn as nn
    MLX_AVAILABLE = True
except ImportError:
    mx = None
    nn = None
    MLX_AVAILABLE = False

logger = logging.getLogger(__name__)

@dataclass
class MetalDeviceCapabilities:
    """M4 Max Metal GPU capabilities and specifications"""
    gpu_cores: int
    unified_memory_gb: int
    memory_bandwidth_gbps: float
    compute_units: int
    max_threads_per_group: int
    max_buffer_size: int
    supports_simd: bool
    supports_fp16: bool
    supports_int8: bool
    gpu_family: int
    architecture: str

@dataclass
class MetalMemoryStats:
    """Metal GPU memory statistics and utilization"""
    allocated_mb: float
    reserved_mb: float
    free_mb: float
    total_unified_mb: float
    peak_allocated_mb: float
    utilization_percent: float
    pressure_level: str  # "normal", "warning", "critical"
    thermal_state: str   # "nominal", "fair", "serious", "critical"

@dataclass
class MetalPerformanceProfile:
    """Performance profiling data for Metal operations"""
    operation_name: str
    execution_time_ms: float
    memory_used_mb: float
    throughput_gflops: float
    efficiency_percent: float
    recommendations: List[str]

class MetalDeviceManager:
    """
    Metal GPU device management and capability detection for M4 Max
    Handles device enumeration, capability detection, and optimization
    """
    
    def __init__(self):
        self.device_capabilities: Optional[MetalDeviceCapabilities] = None
        self.is_m4_max: bool = False
        self.optimization_enabled: bool = False
        self._lock = threading.RLock()
        self._thermal_monitor_active = False
        self._performance_history: List[MetalPerformanceProfile] = []
        self._initialize_device()
        
    def _initialize_device(self):
        """Initialize and detect M4 Max Metal capabilities"""
        try:
            # Detect Apple Silicon architecture
            if platform.machine() != 'arm64' or platform.system() != 'Darwin':
                logger.warning("Metal acceleration requires Apple Silicon on macOS")
                return
                
            # Get system information
            system_info = self._get_system_info()
            
            # Detect M4 Max specifically
            self.is_m4_max = self._detect_m4_max(system_info)
            
            if not self.is_m4_max:
                logger.warning("Optimized for M4 Max, but detected different Apple Silicon")
                
            # Initialize Metal capabilities
            self.device_capabilities = self._detect_metal_capabilities()
            
            if self.device_capabilities:
                logger.info(f"Metal GPU initialized: {self.device_capabilities.gpu_cores} cores, "
                          f"{self.device_capabilities.unified_memory_gb}GB unified memory, "
                          f"{self.device_capabilities.memory_bandwidth_gbps}GB/s bandwidth")
                self.optimization_enabled = True
                
                # Start thermal monitoring if M4 Max detected
                if self.is_m4_max:
                    self._start_thermal_monitoring()
            else:
                logger.error("Failed to initialize Metal GPU capabilities")
                
        except Exception as e:
            logger.error(f"Metal device initialization failed: {e}")
            
    def _get_system_info(self) -> Dict[str, Any]:
        """Get detailed system information"""
        try:
            # Get CPU information
            cpu_info = {}
            try:
                result = subprocess.run(['sysctl', '-n', 'machdep.cpu.brand_string'], 
                                     capture_output=True, text=True, timeout=5)
                cpu_info['brand_string'] = result.stdout.strip()
            except:
                cpu_info['brand_string'] = "Unknown"
                
            # Get memory information
            memory_info = psutil.virtual_memory()
            
            # Get GPU information from system_profiler
            gpu_info = {}
            try:
                result = subprocess.run(['system_profiler', 'SPDisplaysDataType', '-json'], 
                                     capture_output=True, text=True, timeout=10)
                if result.returncode == 0:
                    import json
                    data = json.loads(result.stdout)
                    displays = data.get('SPDisplaysDataType', [])
                    for display in displays:
                        if 'sppci_model' in display:
                            gpu_info['model'] = display['sppci_model']
                            break
            except:
                gpu_info['model'] = "Unknown GPU"
                
            return {
                'cpu_info': cpu_info,
                'memory_info': {
                    'total': memory_info.total,
                    'available': memory_info.available
                },
                'gpu_info': gpu_info,
                'platform': platform.platform(),
                'machine': platform.machine(),
                'processor': platform.processor()
            }
            
        except Exception as e:
            logger.error(f"Failed to get system info: {e}")
            return {}
            
    def _detect_m4_max(self, system_info: Dict[str, Any]) -> bool:
        """Detect if running on M4 Max specifically"""
        try:
            cpu_brand = system_info.get('cpu_info', {}).get('brand_string', '').lower()
            gpu_model = system_info.get('gpu_info', {}).get('model', '').lower()
            
            # M4 Max detection patterns
            m4_max_patterns = [
                'm4 max',
                'apple m4 max',
                'm4max'
            ]
            
            # Check CPU brand string
            for pattern in m4_max_patterns:
                if pattern in cpu_brand:
                    return True
                    
            # Check GPU model (M4 Max has integrated GPU)
            if 'm4' in gpu_model and 'max' in gpu_model:
                return True
                
            # Additional checks for M4 Max characteristics
            # M4 Max typically has 36GB or more unified memory
            total_memory_gb = system_info.get('memory_info', {}).get('total', 0) / (1024**3)
            if total_memory_gb >= 32:  # M4 Max configurations
                # Additional verification needed
                logger.info(f"Detected high memory system ({total_memory_gb:.1f}GB) - likely M4 Max")
                return True
                
        except Exception as e:
            logger.error(f"M4 Max detection failed: {e}")
            
        return False
        
    def _detect_metal_capabilities(self) -> Optional[MetalDeviceCapabilities]:
        """Detect Metal GPU capabilities and specifications"""
        try:
            if not MPS_AVAILABLE:
                logger.warning("Metal Performance Shaders not available")
                return None
                
            # M4 Max specifications (based on Apple's published specs)
            if self.is_m4_max:
                return MetalDeviceCapabilities(
                    gpu_cores=40,  # M4 Max has 40 GPU cores
                    unified_memory_gb=36,  # Base M4 Max configuration
                    memory_bandwidth_gbps=546.0,  # 546 GB/s memory bandwidth
                    compute_units=40,
                    max_threads_per_group=1024,
                    max_buffer_size=4 * 1024 * 1024 * 1024,  # 4GB max buffer
                    supports_simd=True,
                    supports_fp16=True,
                    supports_int8=True,
                    gpu_family=9,  # Apple GPU Family 9
                    architecture="Apple Silicon M4 Max"
                )
            else:
                # Generic Apple Silicon capabilities
                total_memory_gb = psutil.virtual_memory().total / (1024**3)
                return MetalDeviceCapabilities(
                    gpu_cores=16,  # Conservative estimate for other Apple Silicon
                    unified_memory_gb=int(total_memory_gb),
                    memory_bandwidth_gbps=200.0,  # Conservative estimate
                    compute_units=16,
                    max_threads_per_group=512,
                    max_buffer_size=2 * 1024 * 1024 * 1024,  # 2GB max buffer
                    supports_simd=True,
                    supports_fp16=True,
                    supports_int8=True,
                    gpu_family=7,  # Generic Apple GPU Family
                    architecture="Apple Silicon"
                )
                
        except Exception as e:
            logger.error(f"Metal capabilities detection failed: {e}")
            return None
            
    def _start_thermal_monitoring(self):
        """Start thermal monitoring for M4 Max"""
        if self._thermal_monitor_active:
            return
            
        def monitor_thermal():
            self._thermal_monitor_active = True
            while self._thermal_monitor_active:
                try:
                    # Monitor thermal state (simplified - would need more sophisticated monitoring)
                    time.sleep(10)  # Check every 10 seconds
                    
                    # Get CPU temperature if available
                    temp_info = self._get_thermal_state()
                    if temp_info['temperature'] > 85:  # High temperature threshold
                        logger.warning(f"High GPU temperature detected: {temp_info['temperature']}Â°C")
                        
                except Exception as e:
                    logger.error(f"Thermal monitoring error: {e}")
                    
        # Start thermal monitoring in background thread
        thermal_thread = threading.Thread(target=monitor_thermal, daemon=True)
        thermal_thread.start()
        
    def _get_thermal_state(self) -> Dict[str, Any]:
        """Get current thermal state information"""
        try:
            # Get CPU temperature (approximation for GPU thermal state)
            result = subprocess.run(['sysctl', '-n', 'machdep.xcpm.cpu_thermal_state'], 
                                 capture_output=True, text=True, timeout=5)
            thermal_state = int(result.stdout.strip()) if result.returncode == 0 else 0
            
            # Convert thermal state to temperature estimate
            temperature_estimate = 30 + (thermal_state * 15)  # Rough estimation
            
            return {
                'thermal_state': thermal_state,
                'temperature': temperature_estimate,
                'state_description': self._get_thermal_description(thermal_state)
            }
            
        except Exception as e:
            logger.error(f"Failed to get thermal state: {e}")
            return {'thermal_state': 0, 'temperature': 30, 'state_description': 'nominal'}
            
    def _get_thermal_description(self, thermal_state: int) -> str:
        """Convert thermal state number to description"""
        if thermal_state == 0:
            return "nominal"
        elif thermal_state <= 2:
            return "fair"
        elif thermal_state <= 4:
            return "serious"
        else:
            return "critical"
            
    def get_memory_stats(self) -> Optional[MetalMemoryStats]:
        """Get current Metal GPU memory statistics"""
        if not self.optimization_enabled or not MPS_AVAILABLE:
            return None
            
        try:
            if hasattr(torch.backends.mps, 'current_allocated_memory'):
                allocated = torch.backends.mps.current_allocated_memory() / 1024 / 1024  # MB
                reserved = torch.backends.mps.driver_allocated_memory() / 1024 / 1024 if hasattr(torch.backends.mps, 'driver_allocated_memory') else allocated
            else:
                allocated = 0
                reserved = 0
                
            # Get system memory info
            memory = psutil.virtual_memory()
            total_mb = memory.total / 1024 / 1024
            free_mb = memory.available / 1024 / 1024
            
            # Get thermal state
            thermal_info = self._get_thermal_state()
            
            utilization = (allocated / total_mb) * 100 if total_mb > 0 else 0
            
            # Determine pressure level
            pressure_level = "normal"
            if utilization > 80:
                pressure_level = "critical"
            elif utilization > 60:
                pressure_level = "warning"
                
            return MetalMemoryStats(
                allocated_mb=allocated,
                reserved_mb=reserved,
                free_mb=free_mb,
                total_unified_mb=total_mb,
                peak_allocated_mb=allocated,  # Simplified
                utilization_percent=utilization,
                pressure_level=pressure_level,
                thermal_state=thermal_info['state_description']
            )
            
        except Exception as e:
            logger.error(f"Failed to get Metal memory stats: {e}")
            return None
            
    def optimize_for_workload(self, workload_type: str) -> Dict[str, Any]:
        """Optimize Metal configuration for specific workload types"""
        if not self.optimization_enabled:
            return {"optimized": False, "reason": "Metal not available"}
            
        optimizations = {}
        
        try:
            if workload_type == "financial_computation":
                # Optimize for high-precision financial calculations
                optimizations = {
                    "precision_mode": "high",
                    "memory_pool_size": "large",
                    "batch_size_recommendation": 2048 if self.is_m4_max else 1024,
                    "use_fp16": False,  # Financial precision requirements
                    "enable_memory_pooling": True
                }
                
            elif workload_type == "monte_carlo":
                # Optimize for Monte Carlo simulations
                optimizations = {
                    "precision_mode": "balanced",
                    "memory_pool_size": "extra_large",
                    "batch_size_recommendation": 4096 if self.is_m4_max else 2048,
                    "use_fp16": True,  # Can use lower precision for MC
                    "enable_parallel_streams": True
                }
                
            elif workload_type == "matrix_operations":
                # Optimize for linear algebra operations
                optimizations = {
                    "precision_mode": "high",
                    "memory_pool_size": "large",
                    "batch_size_recommendation": 1024 if self.is_m4_max else 512,
                    "use_fp16": False,
                    "enable_tensor_cores": True
                }
                
            elif workload_type == "technical_indicators":
                # Optimize for technical indicator calculations
                optimizations = {
                    "precision_mode": "balanced",
                    "memory_pool_size": "medium",
                    "batch_size_recommendation": 8192 if self.is_m4_max else 4096,
                    "use_fp16": True,
                    "enable_vectorization": True
                }
                
            # Apply optimizations if using PyTorch
            if MPS_AVAILABLE and torch is not None:
                if optimizations.get("enable_memory_pooling", False):
                    # Enable memory pooling (if available)
                    pass  # PyTorch MPS handles this automatically
                    
            optimizations["optimized"] = True
            optimizations["target_device"] = "M4 Max" if self.is_m4_max else "Apple Silicon"
            
            logger.info(f"Applied {workload_type} optimizations: {optimizations}")
            
        except Exception as e:
            logger.error(f"Workload optimization failed: {e}")
            optimizations = {"optimized": False, "error": str(e)}
            
        return optimizations
        
    def benchmark_performance(self, operation: str, *args, **kwargs) -> MetalPerformanceProfile:
        """Benchmark Metal GPU performance for specific operations"""
        start_time = time.time()
        start_memory = self.get_memory_stats()
        
        try:
            # Execute operation (placeholder - would be implemented for specific operations)
            # This would call the actual operation being benchmarked
            time.sleep(0.001)  # Placeholder
            
            end_time = time.time()
            end_memory = self.get_memory_stats()
            
            execution_time_ms = (end_time - start_time) * 1000
            memory_used_mb = (end_memory.allocated_mb - start_memory.allocated_mb) if end_memory and start_memory else 0
            
            # Estimate GFLOPS (simplified calculation)
            estimated_operations = kwargs.get('operations', 1000000)
            throughput_gflops = (estimated_operations / execution_time_ms) * 1000 / 1e9
            
            # Calculate efficiency (simplified)
            theoretical_peak_gflops = 20 if self.is_m4_max else 10  # Rough estimates
            efficiency_percent = min(100, (throughput_gflops / theoretical_peak_gflops) * 100)
            
            # Generate recommendations
            recommendations = self._generate_performance_recommendations(
                execution_time_ms, memory_used_mb, efficiency_percent
            )
            
            profile = MetalPerformanceProfile(
                operation_name=operation,
                execution_time_ms=execution_time_ms,
                memory_used_mb=memory_used_mb,
                throughput_gflops=throughput_gflops,
                efficiency_percent=efficiency_percent,
                recommendations=recommendations
            )
            
            # Store in performance history
            self._performance_history.append(profile)
            if len(self._performance_history) > 100:  # Keep only recent profiles
                self._performance_history.pop(0)
                
            return profile
            
        except Exception as e:
            logger.error(f"Performance benchmarking failed: {e}")
            return MetalPerformanceProfile(
                operation_name=operation,
                execution_time_ms=0,
                memory_used_mb=0,
                throughput_gflops=0,
                efficiency_percent=0,
                recommendations=[f"Benchmarking failed: {str(e)}"]
            )
            
    def _generate_performance_recommendations(self, exec_time: float, memory_used: float, efficiency: float) -> List[str]:
        """Generate performance optimization recommendations"""
        recommendations = []
        
        if efficiency < 30:
            recommendations.append("Consider optimizing algorithm for Metal GPU execution")
            recommendations.append("Check if operation can benefit from vectorization")
            
        if memory_used > 1000:  # > 1GB
            recommendations.append("High memory usage detected - consider batch size reduction")
            recommendations.append("Enable memory pooling to reduce allocation overhead")
            
        if exec_time > 100:  # > 100ms
            recommendations.append("Long execution time - consider algorithm optimization")
            recommendations.append("Check if operation can be parallelized further")
            
        if self.is_m4_max and efficiency < 60:
            recommendations.append("Suboptimal performance on M4 Max - review implementation")
            recommendations.append("Consider using MLX framework for better Apple Silicon optimization")
            
        if not recommendations:
            recommendations.append("Performance appears optimal for current workload")
            
        return recommendations
        
    def get_optimization_status(self) -> Dict[str, Any]:
        """Get current optimization status and recommendations"""
        memory_stats = self.get_memory_stats()
        thermal_info = self._get_thermal_state()
        
        status = {
            "metal_available": MPS_AVAILABLE,
            "optimization_enabled": self.optimization_enabled,
            "device_type": "M4 Max" if self.is_m4_max else "Apple Silicon",
            "gpu_cores": self.device_capabilities.gpu_cores if self.device_capabilities else 0,
            "unified_memory_gb": self.device_capabilities.unified_memory_gb if self.device_capabilities else 0,
            "memory_bandwidth_gbps": self.device_capabilities.memory_bandwidth_gbps if self.device_capabilities else 0,
            "current_memory_usage_mb": memory_stats.allocated_mb if memory_stats else 0,
            "memory_utilization_percent": memory_stats.utilization_percent if memory_stats else 0,
            "thermal_state": thermal_info['state_description'],
            "performance_profiles_count": len(self._performance_history),
            "mlx_available": MLX_AVAILABLE
        }
        
        # Add recommendations
        recommendations = []
        
        if not MPS_AVAILABLE:
            recommendations.append("Install PyTorch with Metal support for GPU acceleration")
            
        if not self.is_m4_max:
            recommendations.append("For optimal performance, use M4 Max hardware")
            
        if memory_stats and memory_stats.utilization_percent > 80:
            recommendations.append("High memory utilization - consider reducing batch sizes")
            
        if thermal_info['thermal_state'] not in ['nominal', 'fair']:
            recommendations.append("Thermal throttling possible - ensure adequate cooling")
            
        if not MLX_AVAILABLE:
            recommendations.append("Install MLX framework for enhanced Apple Silicon optimization")
            
        status["recommendations"] = recommendations
        
        return status

# Global Metal device manager instance
metal_device_manager = MetalDeviceManager()

# Configuration functions
def is_metal_available() -> bool:
    """Check if Metal GPU acceleration is available"""
    return metal_device_manager.optimization_enabled

def is_m4_max_detected() -> bool:
    """Check if M4 Max hardware is detected"""
    return metal_device_manager.is_m4_max

def get_metal_capabilities() -> Optional[MetalDeviceCapabilities]:
    """Get Metal GPU capabilities"""
    return metal_device_manager.device_capabilities

def optimize_for_financial_computing() -> Dict[str, Any]:
    """Optimize Metal configuration for financial computing workloads"""
    return metal_device_manager.optimize_for_workload("financial_computation")

def optimize_for_monte_carlo() -> Dict[str, Any]:
    """Optimize Metal configuration for Monte Carlo simulations"""
    return metal_device_manager.optimize_for_workload("monte_carlo")

def optimize_for_matrix_operations() -> Dict[str, Any]:
    """Optimize Metal configuration for matrix operations"""
    return metal_device_manager.optimize_for_workload("matrix_operations")

def optimize_for_technical_indicators() -> Dict[str, Any]:
    """Optimize Metal configuration for technical indicator calculations"""
    return metal_device_manager.optimize_for_workload("technical_indicators")

@contextmanager
def metal_performance_context(operation_name: str, **kwargs):
    """Context manager for performance monitoring"""
    start_time = time.time()
    start_memory = metal_device_manager.get_memory_stats()
    
    try:
        yield
    finally:
        end_time = time.time()
        end_memory = metal_device_manager.get_memory_stats()
        
        execution_time = (end_time - start_time) * 1000
        memory_delta = (end_memory.allocated_mb - start_memory.allocated_mb) if end_memory and start_memory else 0
        
        logger.info(f"Metal operation '{operation_name}' completed in {execution_time:.2f}ms, "
                   f"memory delta: {memory_delta:.2f}MB")